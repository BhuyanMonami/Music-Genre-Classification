{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"T5kQj9KjYXMR"},"outputs":[],"source":["import os\n","import h5py\n","import librosa\n","import itertools\n","from copy import copy\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from collections import OrderedDict\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"INnAw8hR_V0I"},"outputs":[],"source":["gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","  try:\n","    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048)])\n","  except RuntimeError as e:\n","    print(e)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ndWmJcXpYs0m"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Add\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Activation\n","from tensorflow.keras.layers import PReLU\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import AveragePooling2D, LSTM, Lambda\n","from tensorflow.keras.layers import GlobalAveragePooling2D\n","from tensorflow.keras.layers import GlobalMaxPooling2D\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","from keras.optimizers import SGD\n","from keras.callbacks import EarlyStopping,ModelCheckpoint\n","from google.colab.patches import cv2_imshow\n","from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D\n","from keras.preprocessing import image\n","from keras.initializers import glorot_uniform"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15103,"status":"ok","timestamp":1682838043769,"user":{"displayName":"PRAJWAL DINESH BHAGWAT","userId":"17548301535283757040"},"user_tz":300},"id":"_o51Gu6xdTY9","outputId":"b8a83290-51c3-4829-b54d-b61c96aa1ee4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lMy7XPLjYzSv"},"outputs":[],"source":["# For reproducibility purposes\n","np.random.seed(42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JZ7EH52XY3iP"},"outputs":[],"source":["\"\"\"\n","@description: Method to split a song into multiple songs using overlapping windows\n","\"\"\"\n","def splitsongs(X, y, window = 0.05, overlap = 0.5):\n","    # Empty lists to hold our results\n","    temp_X = []\n","    temp_y = []\n","\n","    # Get the input song array size\n","    xshape = X.shape[0]\n","    chunk = int(xshape*window)\n","    offset = int(chunk*(1.-overlap))\n","    \n","    # Split the song and create new ones on windows\n","    spsong = [X[i:i+chunk] for i in range(0, xshape - chunk + offset, offset)]\n","    for s in spsong:\n","        if s.shape[0] != chunk:\n","            continue\n","\n","        temp_X.append(s)\n","        temp_y.append(y)\n","\n","    return np.array(temp_X), np.array(temp_y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O-GSyammY-cO"},"outputs":[],"source":["\"\"\"\n","@description: Method to convert a list of songs to a np array of melspectrograms\n","\"\"\"\n","def to_melspectrogram(songs, n_fft=1024, hop_length=256):\n","    # Transformation function\n","    melspec = lambda y: librosa.feature.melspectrogram(y=y, n_fft=n_fft,\n","        hop_length=hop_length, n_mels=128)[:,:,np.newaxis]\n","\n","    # map transformation of input songs to melspectrogram using log-scale\n","    tsongs = map(melspec, songs)\n","    # np.array([librosa.power_to_db(s, ref=np.max) for s in list(tsongs)])\n","    return np.array(list(tsongs))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QUUQGHLXZCCH"},"outputs":[],"source":["def split_convert(X, y):\n","    arr_specs, arr_genres = [], []\n","    #song_samples = 660000\n","    \n","    # Convert to spectrograms and split into small windows\n","    for fn, genre in zip(X, y):\n","        signal, sr = librosa.load(fn)\n","        signal = signal[:song_samples]\n","\n","        # Convert to dataset of spectograms/melspectograms\n","        signals, y = splitsongs(signal, genre)\n","\n","        # Convert to \"spec\" representation\n","        specs = to_melspectrogram(signals)\n","\n","        # Save files\n","        arr_genres.extend(y)\n","        arr_specs.extend(specs)\n","    \n","    return np.array(arr_specs), to_categorical(arr_genres)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rGFEQro5ZF0n"},"outputs":[],"source":["def read_data(src_dir, genres, song_samples):    \n","    # Empty array of dicts with the processed features from all files\n","    arr_fn = []\n","    arr_genres = []\n","\n","    # Get file list from the folders\n","    for x,_ in genres.items():\n","        folder = src_dir + x\n","        temp_file_list = os.listdir(folder)\n","        for file in temp_file_list:\n","          file_name = folder + \"/\" + file\n","          arr_fn.append(file_name)\n","          arr_genres.append(genres[x])\n","          \n","    # Split into train and test\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        arr_fn, arr_genres, test_size=0.3, random_state=42, stratify=arr_genres\n","    )\n","    \n","    # Split into small segments and convert to spectrogram\n","    X_train, y_train = split_convert(X_train, y_train)\n","    X_test, y_test = split_convert(X_test, y_test)\n","\n","    return X_train, X_test, y_train, y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mws-32qFZJNO"},"outputs":[],"source":["song_samples = 660000\n","genres = {'metal': 0, 'disco': 1, 'classical': 2, 'hiphop': 3, 'jazz': 4, \n","          'country': 5, 'pop': 6, 'blues': 7, 'reggae': 8, 'rock': 9}\n","\n","# gtzan_dir = '/content/drive/MyDrive/Music_Genre_Classification/data/genres/'          \n","\n","# Prjwal's computer \n","gtzan_dir = '/content/drive/MyDrive/Colab Notebooks/ECE 539/Project/ECE_539_Project/Music_Genre_Classification/data/genres/'\n","\n","# Read the data\n","X_train, X_test, y_train, y_test = read_data(gtzan_dir, genres, song_samples)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1682838692651,"user":{"displayName":"PRAJWAL DINESH BHAGWAT","userId":"17548301535283757040"},"user_tz":300},"id":"fVyHapWYLDWW","outputId":"88f09221-4042-40c3-d132-203b47f81d83"},"outputs":[{"name":"stdout","output_type":"stream","text":["(27261, 128, 129, 1) (11700, 128, 129, 1) (27261, 10) (11700, 10)\n","(27261, 128, 129)\n","(27261, 128, 129)\n"]}],"source":["print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n","print(np.reshape(X_train,((X_train.shape[0],X_train.shape[1],X_train.shape[2]))).shape)\n","# X2_train = np.array(np.reshape(X_train,((X_train.shape[0],X_train.shape[1],X_train.shape[2]))))\n","# X2_test = np.array(np.reshape(X_test,((X_test.shape[0],X_test.shape[1],X_test.shape[2]))))\n","X2_train = np.squeeze(X_train,axis=3)\n","X2_test = np.squeeze(X_test,axis=3)\n","print(X2_train.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":179,"status":"ok","timestamp":1682838692825,"user":{"displayName":"PRAJWAL DINESH BHAGWAT","userId":"17548301535283757040"},"user_tz":300},"id":"cP5S0rtKUDW0","outputId":"eef35ecb-168e-4818-b86a-a47435ba7d25"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Histogram for train and test \n","values, count = np.unique(np.argmax(y_train, axis=1), return_counts=True)\n","plt.bar(values, count)\n","\n","values, count = np.unique(np.argmax(y_test, axis=1), return_counts=True)\n","plt.bar(values, count)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XvfZgMOSUHQo"},"outputs":[],"source":["from tensorflow.keras.utils import Sequence\n","\n","class GTZANGenerator(Sequence):\n","    def __init__(self, X, y, batch_size=64, is_test = False):\n","        self.X = X\n","        self.y = y\n","        self.batch_size = batch_size\n","        self.is_test = is_test\n","    \n","    def __len__(self):\n","        return int(np.ceil(len(self.X)/self.batch_size))\n","    \n","    def __getitem__(self, index):\n","        # Get batch indexes\n","        signals = self.X[index*self.batch_size:(index+1)*self.batch_size]\n","\n","        # Apply data augmentation\n","        if not self.is_test:\n","            signals = self.__augment(signals)\n","        return signals, self.y[index*self.batch_size:(index+1)*self.batch_size]\n","    \n","    def __augment(self, signals, hor_flip = 0.5, random_cutout = 0.5):\n","        spectrograms =  []\n","        for s in signals:\n","            signal = copy(s)\n","            \n","            # Perform horizontal flip\n","            if np.random.rand() < hor_flip:\n","                signal = np.flip(signal, 1)\n","\n","            # Perform random cutoout of some frequency/time\n","            if np.random.rand() < random_cutout:\n","                lines = np.random.randint(signal.shape[0], size=3)\n","                cols = np.random.randint(signal.shape[0], size=4)\n","                signal[lines, :, :] = -80 # dB\n","                signal[:, cols, :] = -80 # dB\n","\n","            spectrograms.append(signal)\n","        return np.array(spectrograms)\n","    \n","    def on_epoch_end(self):\n","        self.indexes = np.arange(len(self.X))\n","        np.random.shuffle(self.indexes)\n","        return None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BdcrcOmZlJMH"},"outputs":[],"source":["#base_model = ResNet50(input_shape=(128, 129, 1))\n","#model = ResNet50(X_train[0].shape, len(genres))\n","#"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6jkZmVAPUMgY"},"outputs":[],"source":["# def conv_block(x, n_filters, pool_size=(2, 2)):\n","#     x = Conv2D(n_filters, (3, 3), strides=(1, 1), padding='same')(x)\n","#     x = Activation('relu')(x)\n","#     x = MaxPooling2D(pool_size=pool_size, strides=pool_size)(x)\n","#     x = Dropout(0.25)(x)\n","#     return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3v7KbGAyUPax"},"outputs":[],"source":["def create_model(input_shape, num_genres):\n","    inpt = Input(shape=input_shape)\n","    x = Lambda(lambda x: x[:,:,:,0], input_shape=(*input_shape, 1))(inpt)\n","    x = LSTM(units=128, dropout=0.05, recurrent_dropout=0.35, return_sequences=True, input_shape=input_shape)(x)\n","    x = LSTM(units=32, dropout=0.05, recurrent_dropout=0.35, return_sequences=True)(x)\n","    # x = LSTM(units=64, dropout=0.05, recurrent_dropout=0.35, return_sequences=True)(x)\n","    # x = LSTM(units=32, dropout=0.05, recurrent_dropout=0.35, return_sequences=False)(x)\n","    x = Flatten()(x)\n","    x = Dropout(0.3)(x)\n","    x = Dense(512, activation='relu', \n","              kernel_regularizer=tf.keras.regularizers.l2(0.02))(x)\n","    x = Dropout(0.25)(x)\n","    predictions = Dense(num_genres, \n","                        activation='softmax', \n","                        kernel_regularizer=tf.keras.regularizers.l2(0.02))(x)\n","    \n","    model = Model(inputs=inpt, outputs=predictions)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3496,"status":"ok","timestamp":1682838696317,"user":{"displayName":"PRAJWAL DINESH BHAGWAT","userId":"17548301535283757040"},"user_tz":300},"id":"SkaPrDDzUT0Q","outputId":"959b1c98-d2b7-4fc4-d297-adb6ccc82821"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]}],"source":["#print(input_shape)\n","model = create_model(X_train[0].shape, len(genres))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1682838696317,"user":{"displayName":"PRAJWAL DINESH BHAGWAT","userId":"17548301535283757040"},"user_tz":300},"id":"7-jvsgDuuPca","outputId":"afa1e55a-6c56-4012-a1a9-2c60db987e5b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 128, 129, 1)]     0         \n","                                                                 \n"," lambda (Lambda)             (None, 128, 129)          0         \n","                                                                 \n"," lstm (LSTM)                 (None, 128, 256)          395264    \n","                                                                 \n"," lstm_1 (LSTM)               (None, 128, 128)          197120    \n","                                                                 \n"," lstm_2 (LSTM)               (None, 128, 64)           49408     \n","                                                                 \n"," lstm_3 (LSTM)               (None, 32)                12416     \n","                                                                 \n"," flatten (Flatten)           (None, 32)                0         \n","                                                                 \n"," dropout (Dropout)           (None, 32)                0         \n","                                                                 \n"," dense (Dense)               (None, 512)               16896     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                5130      \n","                                                                 \n","=================================================================\n","Total params: 676,234\n","Trainable params: 676,234\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"LSDQEUs_yfse"},"source":["Loss function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GBJqlnpCyOKb"},"outputs":[],"source":["model.compile(loss=tf.keras.losses.categorical_crossentropy,\n","              optimizer=tf.keras.optimizers.Adam(),\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jIXwJN8bym7n"},"outputs":[],"source":["reduceLROnPlat = ReduceLROnPlateau(\n","    monitor='val_loss', \n","    factor=0.95,\n","    patience=30,\n","    verbose=1,\n","    mode='min',\n","    min_delta=0.0001,\n","    cooldown=2,\n","    min_lr=1e-6\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"juyoG_QRyqoe"},"outputs":[],"source":["# Generators\n","batch_size = 128\n","train_generator = GTZANGenerator(X_train, y_train)\n","steps_per_epoch = np.ceil(len(X_train)/batch_size)\n","\n","validation_generator = GTZANGenerator(X_test, y_test)\n","val_steps = np.ceil(len(X_test)/batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"WjAhPJb1yt2t","outputId":"59d88b39-d13f-4c44-b9d2-aa8f736df813"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/150\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-21-c619abd23725>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  hist = model.fit_generator(\n"]},{"name":"stdout","output_type":"stream","text":["213/213 [==============================] - 339s 2s/step - loss: 2.6273 - accuracy: 0.1288 - val_loss: 2.3321 - val_accuracy: 0.1061 - lr: 0.0010\n","Epoch 2/150\n","213/213 [==============================] - 322s 2s/step - loss: 2.3129 - accuracy: 0.1102 - val_loss: 2.3059 - val_accuracy: 0.1126 - lr: 0.0010\n","Epoch 3/150\n","213/213 [==============================] - 323s 2s/step - loss: 2.3043 - accuracy: 0.1252 - val_loss: 2.3029 - val_accuracy: 0.1126 - lr: 0.0010\n","Epoch 4/150\n","213/213 [==============================] - 324s 2s/step - loss: 2.3035 - accuracy: 0.0943 - val_loss: 2.3028 - val_accuracy: 0.1126 - lr: 0.0010\n","Epoch 5/150\n","213/213 [==============================] - 323s 2s/step - loss: 2.3036 - accuracy: 0.0680 - val_loss: 2.3024 - val_accuracy: 0.1126 - lr: 0.0010\n","Epoch 6/150\n","213/213 [==============================] - 324s 2s/step - loss: 2.3024 - accuracy: 0.1027 - val_loss: 2.3021 - val_accuracy: 0.1126 - lr: 0.0010\n","Epoch 7/150\n","213/213 [==============================] - 324s 2s/step - loss: 2.3038 - accuracy: 0.0977 - val_loss: 2.3055 - val_accuracy: 0.0795 - lr: 0.0010\n","Epoch 8/150\n","213/213 [==============================] - 322s 2s/step - loss: 2.3060 - accuracy: 0.0854 - val_loss: 2.3036 - val_accuracy: 0.0795 - lr: 0.0010\n","Epoch 9/150\n","213/213 [==============================] - 323s 2s/step - loss: 2.3050 - accuracy: 0.0650 - val_loss: 2.3023 - val_accuracy: 0.0861 - lr: 0.0010\n","Epoch 10/150\n","213/213 [==============================] - 323s 2s/step - loss: 2.3025 - accuracy: 0.0973 - val_loss: 2.3018 - val_accuracy: 0.1192 - lr: 0.0010\n","Epoch 11/150\n","213/213 [==============================] - 320s 2s/step - loss: 2.3028 - accuracy: 0.0855 - val_loss: 2.3024 - val_accuracy: 0.0861 - lr: 0.0010\n","Epoch 12/150\n","213/213 [==============================] - 321s 2s/step - loss: 2.3027 - accuracy: 0.1002 - val_loss: 2.3028 - val_accuracy: 0.0795 - lr: 0.0010\n","Epoch 13/150\n","213/213 [==============================] - 321s 2s/step - loss: 2.3037 - accuracy: 0.0918 - val_loss: 2.3027 - val_accuracy: 0.0795 - lr: 0.0010\n","Epoch 14/150\n","213/213 [==============================] - 323s 2s/step - loss: 2.3036 - accuracy: 0.0936 - val_loss: 2.3026 - val_accuracy: 0.1058 - lr: 0.0010\n","Epoch 15/150\n","213/213 [==============================] - 323s 2s/step - loss: 2.3033 - accuracy: 0.1032 - val_loss: 2.3027 - val_accuracy: 0.1058 - lr: 0.0010\n","Epoch 16/150\n","213/213 [==============================] - 323s 2s/step - loss: 2.3025 - accuracy: 0.0962 - val_loss: 2.3029 - val_accuracy: 0.1058 - lr: 0.0010\n","Epoch 17/150\n","213/213 [==============================] - 324s 2s/step - loss: 2.3046 - accuracy: 0.0913 - val_loss: 2.3027 - val_accuracy: 0.1192 - lr: 0.0010\n","Epoch 18/150\n","213/213 [==============================] - 324s 2s/step - loss: 2.3026 - accuracy: 0.0887 - val_loss: 2.3029 - val_accuracy: 0.1058 - lr: 0.0010\n","Epoch 19/150\n","213/213 [==============================] - 319s 1s/step - loss: 2.3047 - accuracy: 0.0978 - val_loss: 2.3029 - val_accuracy: 0.1058 - lr: 0.0010\n","Epoch 20/150\n","213/213 [==============================] - ETA: 0s - loss: 2.3021 - accuracy: 0.0957\n","Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n","213/213 [==============================] - 320s 2s/step - loss: 2.3021 - accuracy: 0.0957 - val_loss: 2.3031 - val_accuracy: 0.0795 - lr: 0.0010\n","Epoch 21/150\n","213/213 [==============================] - 321s 2s/step - loss: 2.3035 - accuracy: 0.1015 - val_loss: 2.3031 - val_accuracy: 0.0795 - lr: 9.5000e-04\n","Epoch 22/150\n","213/213 [==============================] - 326s 2s/step - loss: 2.3030 - accuracy: 0.0903 - val_loss: 2.3033 - val_accuracy: 0.0795 - lr: 9.5000e-04\n","Epoch 23/150\n","213/213 [==============================] - 324s 2s/step - loss: 2.3044 - accuracy: 0.0966 - val_loss: 2.3032 - val_accuracy: 0.0861 - lr: 9.5000e-04\n","Epoch 24/150\n","213/213 [==============================] - 324s 2s/step - loss: 2.3034 - accuracy: 0.0960 - val_loss: 2.3037 - val_accuracy: 0.0861 - lr: 9.5000e-04\n","Epoch 25/150\n","213/213 [==============================] - 322s 2s/step - loss: 2.3039 - accuracy: 0.1050 - val_loss: 2.3029 - val_accuracy: 0.0861 - lr: 9.5000e-04\n","Epoch 26/150\n","213/213 [==============================] - 321s 2s/step - loss: 2.3031 - accuracy: 0.1065 - val_loss: 2.3033 - val_accuracy: 0.0861 - lr: 9.5000e-04\n","Epoch 27/150\n","213/213 [==============================] - 318s 1s/step - loss: 2.3040 - accuracy: 0.0796 - val_loss: 2.3031 - val_accuracy: 0.0861 - lr: 9.5000e-04\n","Epoch 28/150\n","213/213 [==============================] - 317s 1s/step - loss: 2.3031 - accuracy: 0.0995 - val_loss: 2.3034 - val_accuracy: 0.0861 - lr: 9.5000e-04\n","Epoch 29/150\n","213/213 [==============================] - 318s 1s/step - loss: 2.3030 - accuracy: 0.0964 - val_loss: 2.3029 - val_accuracy: 0.0861 - lr: 9.5000e-04\n","Epoch 30/150\n","213/213 [==============================] - 319s 1s/step - loss: 2.3030 - accuracy: 0.1024 - val_loss: 2.3037 - val_accuracy: 0.0861 - lr: 9.5000e-04\n","Epoch 31/150\n","213/213 [==============================] - ETA: 0s - loss: 2.3030 - accuracy: 0.0906\n","Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n","213/213 [==============================] - 319s 1s/step - loss: 2.3030 - accuracy: 0.0906 - val_loss: 2.3033 - val_accuracy: 0.0861 - lr: 9.5000e-04\n","Epoch 32/150\n","213/213 [==============================] - 319s 1s/step - loss: 2.3041 - accuracy: 0.0924 - val_loss: 2.3035 - val_accuracy: 0.0861 - lr: 9.0250e-04\n","Epoch 33/150\n","213/213 [==============================] - 320s 2s/step - loss: 2.3040 - accuracy: 0.1010 - val_loss: 2.3028 - val_accuracy: 0.0861 - lr: 9.0250e-04\n","Epoch 34/150\n","213/213 [==============================] - 320s 2s/step - loss: 2.3026 - accuracy: 0.0792 - val_loss: 2.3029 - val_accuracy: 0.0861 - lr: 9.0250e-04\n","Epoch 35/150\n","213/213 [==============================] - 321s 2s/step - loss: 2.3033 - accuracy: 0.1000 - val_loss: 2.3033 - val_accuracy: 0.0927 - lr: 9.0250e-04\n","Epoch 36/150\n","213/213 [==============================] - 321s 2s/step - loss: 2.3035 - accuracy: 0.0986 - val_loss: 2.3030 - val_accuracy: 0.0927 - lr: 9.0250e-04\n","Epoch 37/150\n","213/213 [==============================] - 321s 2s/step - loss: 2.3027 - accuracy: 0.0988 - val_loss: 2.3031 - val_accuracy: 0.0994 - lr: 9.0250e-04\n","Epoch 38/150\n","213/213 [==============================] - 323s 2s/step - loss: 2.3027 - accuracy: 0.0871 - val_loss: 2.3028 - val_accuracy: 0.0994 - lr: 9.0250e-04\n","Epoch 39/150\n","213/213 [==============================] - 322s 2s/step - loss: 2.3026 - accuracy: 0.1048 - val_loss: 2.3035 - val_accuracy: 0.0795 - lr: 9.0250e-04\n","Epoch 40/150\n","213/213 [==============================] - 319s 1s/step - loss: 2.3037 - accuracy: 0.0888 - val_loss: 2.3032 - val_accuracy: 0.0795 - lr: 9.0250e-04\n","Epoch 41/150\n","213/213 [==============================] - 321s 2s/step - loss: 2.3027 - accuracy: 0.1041 - val_loss: 2.3030 - val_accuracy: 0.0795 - lr: 9.0250e-04\n","Epoch 42/150\n","213/213 [==============================] - ETA: 0s - loss: 2.3037 - accuracy: 0.0848\n","Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n","213/213 [==============================] - 322s 2s/step - loss: 2.3037 - accuracy: 0.0848 - val_loss: 2.3030 - val_accuracy: 0.0994 - lr: 9.0250e-04\n","Epoch 43/150\n","213/213 [==============================] - 322s 2s/step - loss: 2.3029 - accuracy: 0.0998 - val_loss: 2.3031 - val_accuracy: 0.0795 - lr: 8.5737e-04\n","Epoch 44/150\n","213/213 [==============================] - 320s 2s/step - loss: 2.3047 - accuracy: 0.0997 - val_loss: 2.3037 - val_accuracy: 0.0795 - lr: 8.5737e-04\n","Epoch 45/150\n","213/213 [==============================] - 319s 1s/step - loss: 2.3025 - accuracy: 0.1109 - val_loss: 2.3035 - val_accuracy: 0.0795 - lr: 8.5737e-04\n","Epoch 46/150\n","213/213 [==============================] - 320s 2s/step - loss: 2.3035 - accuracy: 0.0954 - val_loss: 2.3035 - val_accuracy: 0.0795 - lr: 8.5737e-04\n","Epoch 47/150\n","213/213 [==============================] - 319s 1s/step - loss: 2.3034 - accuracy: 0.0701 - val_loss: 2.3024 - val_accuracy: 0.1126 - lr: 8.5737e-04\n","Epoch 48/150\n","213/213 [==============================] - 319s 1s/step - loss: 2.3036 - accuracy: 0.0895 - val_loss: 2.3028 - val_accuracy: 0.1126 - lr: 8.5737e-04\n","Epoch 49/150\n","213/213 [==============================] - 319s 1s/step - loss: 2.3034 - accuracy: 0.1009 - val_loss: 2.3030 - val_accuracy: 0.0795 - lr: 8.5737e-04\n","Epoch 50/150\n","213/213 [==============================] - 319s 1s/step - loss: 2.3039 - accuracy: 0.0759 - val_loss: 2.3029 - val_accuracy: 0.1060 - lr: 8.5737e-04\n","Epoch 51/150\n","213/213 [==============================] - 329s 2s/step - loss: 2.3031 - accuracy: 0.0787 - val_loss: 2.3024 - val_accuracy: 0.1192 - lr: 8.5737e-04\n","Epoch 52/150\n","213/213 [==============================] - 322s 2s/step - loss: 2.3034 - accuracy: 0.0924 - val_loss: 2.3028 - val_accuracy: 0.0795 - lr: 8.5737e-04\n","Epoch 53/150\n","213/213 [==============================] - ETA: 0s - loss: 2.3032 - accuracy: 0.0959\n","Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n","213/213 [==============================] - 323s 2s/step - loss: 2.3032 - accuracy: 0.0959 - val_loss: 2.3022 - val_accuracy: 0.0795 - lr: 8.5737e-04\n","Epoch 54/150\n","213/213 [==============================] - 322s 2s/step - loss: 2.3032 - accuracy: 0.0705 - val_loss: 2.3026 - val_accuracy: 0.0994 - lr: 8.1451e-04\n","Epoch 55/150\n","213/213 [==============================] - 323s 2s/step - loss: 2.3039 - accuracy: 0.1042 - val_loss: 2.3023 - val_accuracy: 0.0994 - lr: 8.1451e-04\n","Epoch 56/150\n","213/213 [==============================] - 322s 2s/step - loss: 2.3034 - accuracy: 0.0709 - val_loss: 2.3024 - val_accuracy: 0.1126 - lr: 8.1451e-04\n","Epoch 57/150\n","213/213 [==============================] - 321s 2s/step - loss: 2.3027 - accuracy: 0.1010 - val_loss: 2.3018 - val_accuracy: 0.1126 - lr: 8.1451e-04\n","Epoch 58/150\n","213/213 [==============================] - 324s 2s/step - loss: 2.3034 - accuracy: 0.1057 - val_loss: 2.3020 - val_accuracy: 0.1126 - lr: 8.1451e-04\n","Epoch 59/150\n","213/213 [==============================] - 323s 2s/step - loss: 2.3038 - accuracy: 0.0996 - val_loss: 2.3021 - val_accuracy: 0.1126 - lr: 8.1451e-04\n","Epoch 60/150\n","213/213 [==============================] - 322s 2s/step - loss: 2.3021 - accuracy: 0.1201 - val_loss: 2.3027 - val_accuracy: 0.1126 - lr: 8.1451e-04\n","Epoch 61/150\n","213/213 [==============================] - 324s 2s/step - loss: 2.3023 - accuracy: 0.0934 - val_loss: 2.3032 - val_accuracy: 0.1126 - lr: 8.1451e-04\n","Epoch 62/150\n","213/213 [==============================] - 321s 2s/step - loss: 2.3042 - accuracy: 0.0794 - val_loss: 2.3029 - val_accuracy: 0.1126 - lr: 8.1451e-04\n","Epoch 63/150\n","213/213 [==============================] - 322s 2s/step - loss: 2.3037 - accuracy: 0.0831 - val_loss: 2.3029 - val_accuracy: 0.0994 - lr: 8.1451e-04\n","Epoch 64/150\n","213/213 [==============================] - ETA: 0s - loss: 2.3038 - accuracy: 0.0907\n","Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n","213/213 [==============================] - 324s 2s/step - loss: 2.3038 - accuracy: 0.0907 - val_loss: 2.3028 - val_accuracy: 0.1126 - lr: 8.1451e-04\n","Epoch 65/150\n","213/213 [==============================] - 322s 2s/step - loss: 2.3030 - accuracy: 0.1044 - val_loss: 2.3034 - val_accuracy: 0.0861 - lr: 7.7378e-04\n","Epoch 66/150\n","213/213 [==============================] - 322s 2s/step - loss: 2.3026 - accuracy: 0.0944 - val_loss: 2.3034 - val_accuracy: 0.0795 - lr: 7.7378e-04\n","Epoch 67/150\n","213/213 [==============================] - 322s 2s/step - loss: 2.3030 - accuracy: 0.1020 - val_loss: 2.3035 - val_accuracy: 0.0795 - lr: 7.7378e-04\n","Epoch 68/150\n","213/213 [==============================] - 322s 2s/step - loss: 2.3027 - accuracy: 0.1169 - val_loss: 2.3038 - val_accuracy: 0.0795 - lr: 7.7378e-04\n","Epoch 69/150\n","213/213 [==============================] - 323s 2s/step - loss: 2.3034 - accuracy: 0.1070 - val_loss: 2.3034 - val_accuracy: 0.0795 - lr: 7.7378e-04\n","Epoch 70/150\n","213/213 [==============================] - 322s 2s/step - loss: 2.3034 - accuracy: 0.0985 - val_loss: 2.3032 - val_accuracy: 0.0795 - lr: 7.7378e-04\n","Epoch 71/150\n","213/213 [==============================] - 321s 2s/step - loss: 2.3026 - accuracy: 0.1068 - val_loss: 2.3029 - val_accuracy: 0.0795 - lr: 7.7378e-04\n","Epoch 72/150\n","213/213 [==============================] - 322s 2s/step - loss: 2.3042 - accuracy: 0.0809 - val_loss: 2.3027 - val_accuracy: 0.0795 - lr: 7.7378e-04\n","Epoch 73/150\n","213/213 [==============================] - 322s 2s/step - loss: 2.3021 - accuracy: 0.0831 - val_loss: 2.3026 - val_accuracy: 0.0795 - lr: 7.7378e-04\n","Epoch 74/150\n","213/213 [==============================] - 321s 2s/step - loss: 2.3030 - accuracy: 0.0976 - val_loss: 2.3030 - val_accuracy: 0.0795 - lr: 7.7378e-04\n","Epoch 75/150\n","213/213 [==============================] - ETA: 0s - loss: 2.3033 - accuracy: 0.1050\n","Epoch 75: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n","213/213 [==============================] - 322s 2s/step - loss: 2.3033 - accuracy: 0.1050 - val_loss: 2.3033 - val_accuracy: 0.0795 - lr: 7.7378e-04\n","Epoch 76/150\n","213/213 [==============================] - 322s 2s/step - loss: 2.3041 - accuracy: 0.0911 - val_loss: 2.3029 - val_accuracy: 0.0795 - lr: 7.3509e-04\n","Epoch 77/150\n","213/213 [==============================] - 322s 2s/step - loss: 2.3033 - accuracy: 0.0977 - val_loss: 2.3030 - val_accuracy: 0.0795 - lr: 7.3509e-04\n","Epoch 78/150\n","213/213 [==============================] - 321s 2s/step - loss: 2.3030 - accuracy: 0.0978 - val_loss: 2.3034 - val_accuracy: 0.0795 - lr: 7.3509e-04\n","Epoch 79/150\n","213/213 [==============================] - 321s 2s/step - loss: 2.3025 - accuracy: 0.0880 - val_loss: 2.3034 - val_accuracy: 0.0795 - lr: 7.3509e-04\n","Epoch 80/150\n","213/213 [==============================] - 321s 2s/step - loss: 2.3035 - accuracy: 0.0957 - val_loss: 2.3035 - val_accuracy: 0.0795 - lr: 7.3509e-04\n","Epoch 81/150\n","213/213 [==============================] - 321s 2s/step - loss: 2.3027 - accuracy: 0.1097 - val_loss: 2.3042 - val_accuracy: 0.1058 - lr: 7.3509e-04\n","Epoch 82/150\n","213/213 [==============================] - 322s 2s/step - loss: 2.3037 - accuracy: 0.0741 - val_loss: 2.3036 - val_accuracy: 0.1058 - lr: 7.3509e-04\n","Epoch 83/150\n","213/213 [==============================] - 326s 2s/step - loss: 2.3024 - accuracy: 0.1042 - val_loss: 2.3036 - val_accuracy: 0.1058 - lr: 7.3509e-04\n","Epoch 84/150\n","213/213 [==============================] - 326s 2s/step - loss: 2.3033 - accuracy: 0.1159 - val_loss: 2.3033 - val_accuracy: 0.1058 - lr: 7.3509e-04\n","Epoch 85/150\n","213/213 [==============================] - 326s 2s/step - loss: 2.3027 - accuracy: 0.0935 - val_loss: 2.3029 - val_accuracy: 0.1058 - lr: 7.3509e-04\n","Epoch 86/150\n","213/213 [==============================] - ETA: 0s - loss: 2.3035 - accuracy: 0.0952\n","Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n","213/213 [==============================] - 326s 2s/step - loss: 2.3035 - accuracy: 0.0952 - val_loss: 2.3027 - val_accuracy: 0.0927 - lr: 7.3509e-04\n","Epoch 87/150\n","213/213 [==============================] - 327s 2s/step - loss: 2.3035 - accuracy: 0.0845 - val_loss: 2.3028 - val_accuracy: 0.0861 - lr: 6.9834e-04\n","Epoch 88/150\n","213/213 [==============================] - 327s 2s/step - loss: 2.3028 - accuracy: 0.1008 - val_loss: 2.3032 - val_accuracy: 0.0861 - lr: 6.9834e-04\n","Epoch 89/150\n","213/213 [==============================] - 327s 2s/step - loss: 2.3021 - accuracy: 0.1176 - val_loss: 2.3036 - val_accuracy: 0.0861 - lr: 6.9834e-04\n","Epoch 90/150\n","213/213 [==============================] - 326s 2s/step - loss: 2.3036 - accuracy: 0.0994 - val_loss: 2.3033 - val_accuracy: 0.0861 - lr: 6.9834e-04\n","Epoch 91/150\n","213/213 [==============================] - 327s 2s/step - loss: 2.3028 - accuracy: 0.1139 - val_loss: 2.3034 - val_accuracy: 0.0861 - lr: 6.9834e-04\n","Epoch 92/150\n","213/213 [==============================] - 327s 2s/step - loss: 2.3033 - accuracy: 0.0938 - val_loss: 2.3027 - val_accuracy: 0.0861 - lr: 6.9834e-04\n","Epoch 93/150\n","213/213 [==============================] - 327s 2s/step - loss: 2.3045 - accuracy: 0.0896 - val_loss: 2.3025 - val_accuracy: 0.0861 - lr: 6.9834e-04\n","Epoch 94/150\n","213/213 [==============================] - 327s 2s/step - loss: 2.3026 - accuracy: 0.1161 - val_loss: 2.3028 - val_accuracy: 0.0861 - lr: 6.9834e-04\n","Epoch 95/150\n","196/213 [==========================>...] - ETA: 24s - loss: 2.3032 - accuracy: 0.0988"]}],"source":["hist = model.fit_generator(\n","    train_generator,\n","    steps_per_epoch=steps_per_epoch,\n","    validation_data=validation_generator,\n","    validation_steps=val_steps,\n","    epochs=300,\n","    verbose=1,\n","    callbacks=[reduceLROnPlat])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cQAqLAEPB1cs"},"outputs":[],"source":["score = model.evaluate(X_test, y_test, verbose=0)\n","print(\"val_loss = {:.3f} and val_acc = {:.3f}\".format(score[0], score[1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zfT71XUKCGeY"},"outputs":[],"source":["plt.figure(figsize=(15,7))\n","\n","plt.subplot(1,2,1)\n","plt.plot(hist.history['accuracy'], label='train')\n","plt.plot(hist.history['val_accuracy'], label='validation')\n","plt.title('Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.subplot(1,2,2)\n","plt.plot(hist.history['loss'], label='train')\n","plt.plot(hist.history['val_loss'], label='validation')\n","plt.title('Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yl8pMUHdCK88"},"outputs":[],"source":["def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CLu-K1YOCRp5"},"outputs":[],"source":["preds = np.argmax(model.predict(X_test), axis = 1)\n","y_orig = np.argmax(y_test, axis = 1)\n","cm = confusion_matrix(preds, y_orig)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pGA8Xk4fCWGI"},"outputs":[],"source":["keys = OrderedDict(sorted(genres.items(), key=lambda t: t[1])).keys()\n","\n","plt.figure(figsize=(10,10))\n","plot_confusion_matrix(cm, keys, normalize=True)"]},{"cell_type":"markdown","metadata":{"id":"UrK7MEvJCcGI"},"source":["Majority Vote"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QtPXPPtRCii4"},"outputs":[],"source":["def majority_vote(scores):\n","    values, counts = np.unique(scores,return_counts=True)\n","    ind = np.argmax(counts)\n","    return values[ind]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fd5F7HctCmYD"},"outputs":[],"source":["preds = model.predict(X_test, batch_size=128, verbose=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Q6-y8ADCpKR"},"outputs":[],"source":["# Each sound was divided into 39 segments in our custom function\n","scores_songs = np.split(np.argmax(preds, axis=1), 300)\n","scores_songs = [majority_vote(scores) for scores in scores_songs]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BEx1PttSCsP0"},"outputs":[],"source":["# Same analysis for split\n","label = np.split(np.argmax(y_test, axis=1), 300)\n","label = [majority_vote(l) for l in label]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nzY69XtaCu0T"},"outputs":[],"source":["# from sklearn.metrics import accuracy_score\n","\n","# print(\"majority voting system (acc) = {:.3f}\".format(accuracy_score(label, scores_songs)))\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_recall_fscore_support\n","print(\"majority voting system (acc) = {:.3f}\".format(accuracy_score(label, scores_songs)))\n","print(\"precision recall f1 score\",precision_recall_fscore_support(label, scores_songs, average='macro'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hXbmdhIqCy08"},"outputs":[],"source":["# Save the model\n","model.save('../models/resnet.h5')"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1UxmInq38h5NX720RRMQmeToD6jR3UM06","timestamp":1682728206700},{"file_id":"1b9fa1XMJdkVbNXMKUgBRCLBFc5haJI9Q","timestamp":1682720948033},{"file_id":"1Kd9vUWjdBWqjGVNVJN742trNndkukaU0","timestamp":1682713383015}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}