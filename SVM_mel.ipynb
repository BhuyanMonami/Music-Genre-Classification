{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 16:22:42.955267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 16:22:43.034028: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "from decimal import Decimal\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import lightgbm as lgbm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import os\n",
    "import h5py\n",
    "import librosa\n",
    "import itertools\n",
    "from copy import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Add\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import PReLU\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import AveragePooling2D, LSTM, Lambda\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "#from google.colab.patches import cv2_imshow\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D\n",
    "from keras.preprocessing import image\n",
    "from keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility purposes\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@description: Method to split a song into multiple songs using overlapping windows\n",
    "\"\"\"\n",
    "def splitsongs(X, y, window = 0.05, overlap = 0.5):\n",
    "    # Empty lists to hold our results\n",
    "    temp_X = []\n",
    "    temp_y = []\n",
    "\n",
    "    # Get the input song array size\n",
    "    xshape = X.shape[0]\n",
    "    chunk = int(xshape*window)\n",
    "    offset = int(chunk*(1.-overlap))\n",
    "    \n",
    "    # Split the song and create new ones on windows\n",
    "    spsong = [X[i:i+chunk] for i in range(0, xshape - chunk + offset, offset)]\n",
    "    for s in spsong:\n",
    "        if s.shape[0] != chunk:\n",
    "            continue\n",
    "\n",
    "        temp_X.append(s)\n",
    "        temp_y.append(y)\n",
    "\n",
    "    return np.array(temp_X), np.array(temp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@description: Method to convert a list of songs to a np array of melspectrograms\n",
    "\"\"\"\n",
    "def to_melspectrogram(songs, n_fft=1024, hop_length=256):\n",
    "    # Transformation function\n",
    "    melspec = lambda y: librosa.feature.melspectrogram(y=y, n_fft=n_fft,\n",
    "        hop_length=hop_length, n_mels=128)[:,:,np.newaxis]\n",
    "\n",
    "    # map transformation of input songs to melspectrogram using log-scale\n",
    "    tsongs = map(melspec, songs)\n",
    "    # np.array([librosa.power_to_db(s, ref=np.max) for s in list(tsongs)])\n",
    "    return np.array(list(tsongs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_convert(X, y):\n",
    "    arr_specs, arr_genres = [], []\n",
    "    #song_samples = 660000\n",
    "    \n",
    "    # Convert to spectrograms and split into small windows\n",
    "    for fn, genre in zip(X, y):\n",
    "        signal, sr = librosa.load(fn)\n",
    "        signal = signal[:song_samples]\n",
    "\n",
    "        # Convert to dataset of spectograms/melspectograms\n",
    "        signals, y = splitsongs(signal, genre)\n",
    "\n",
    "        # Convert to \"spec\" representation\n",
    "        specs = to_melspectrogram(signals)\n",
    "\n",
    "        # Save files\n",
    "        arr_genres.extend(y)\n",
    "        arr_specs.extend(specs)\n",
    "    \n",
    "    return np.array(arr_specs), to_categorical(arr_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(src_dir, genres, song_samples):    \n",
    "    # Empty array of dicts with the processed features from all files\n",
    "    arr_fn = []\n",
    "    arr_genres = []\n",
    "\n",
    "    # Get file list from the folders\n",
    "    for x,_ in genres.items():\n",
    "        folder = src_dir + x\n",
    "        temp_file_list = os.listdir(folder)\n",
    "        for file in temp_file_list:\n",
    "          file_name = folder + \"/\" + file\n",
    "          arr_fn.append(file_name)\n",
    "          arr_genres.append(genres[x])\n",
    "          \n",
    "    # Split into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        arr_fn, arr_genres, test_size=0.3, random_state=42, stratify=arr_genres\n",
    "    )\n",
    "    \n",
    "    # Split into small segments and convert to spectrogram\n",
    "    X_train, y_train = split_convert(X_train, y_train)\n",
    "    X_test, y_test = split_convert(X_test, y_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_samples = 660000\n",
    "genres = {'metal': 0, 'disco': 1, 'classical': 2, 'hiphop': 3, 'jazz': 4, \n",
    "          'country': 5, 'pop': 6, 'blues': 7, 'reggae': 8, 'rock': 9}\n",
    "\n",
    "# gtzan_dir = '/content/drive/MyDrive/Music_Genre_Classification/data/genres/'          \n",
    "\n",
    "# Prjwal's computer \n",
    "gtzan_dir = '/home/bhuyan2/ECE_539/data/genres/'\n",
    "\n",
    "# Read the data\n",
    "X_train, X_test, y_train, y_test = read_data(gtzan_dir, genres, song_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27261, 128, 129, 1) (11700, 128, 129, 1) (27261, 10) (11700, 10)\n",
      "(27261, 16512) (11700, 16512)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "#print(np.reshape(X_train,((X_train.shape[0],X_train.shape[1],X_train.shape[2]))).shape)\n",
    "# X2_train = np.array(np.reshape(X_train,((X_train.shape[0],X_train.shape[1],X_train.shape[2]))))\n",
    "# X2_test = np.array(np.reshape(X_test,((X_test.shape[0],X_test.shape[1],X_test.shape[2]))))\n",
    "#X2_train = np.squeeze(X_train,axis=3)\n",
    "#X2_test = np.squeeze(X_test,axis=3)\n",
    "#print(X2_train.shape)\n",
    "X_train_2d = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_2d = X_test.reshape(X_test.shape[0], -1)\n",
    "print(X_train_2d.shape,X_test_2d.shape )\n",
    "\n",
    "y_train = np.argmax(y_train, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram for train and test \n",
    "values, count = np.unique(y_train, return_counts=True)\n",
    "plt.bar(values, count)\n",
    "\n",
    "values, count = np.unique(y_test, return_counts=True)\n",
    "plt.bar(values, count)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"cls__C\": [0.5, 1, 2, 5],\n",
    "    \"cls__kernel\": ['rbf', 'linear', 'sigmoid'],\n",
    "}\n",
    "\n",
    "pipe_svm = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('cls', SVC())\n",
    "])\n",
    "\n",
    "grid_svm = GridSearchCV(pipe_svm, params, scoring='accuracy', n_jobs=-1, cv=5)\n",
    "grid_svm.fit(X_train_2d, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = grid_svm.predict(X_test)\n",
    "print(\"best score on validation set (accuracy) = {:.4f}\".format(grid_svm.best_score_))\n",
    "print(\"best score on test set (accuracy) = {:.4f}\".format(accuracy_score(y_test, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, preds)\n",
    "classes = ['metal', 'disco', 'classical', 'hiphop', 'jazz', 'country', 'pop', 'blues', 'reggae', 'rock']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plot_confusion_matrix(cm, classes, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, preds, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "print(\"Precision: {:.2f}\".format(precision))\n",
    "print(\"Recall: {:.2f}\".format(recall))\n",
    "print(\"F1 Score: {:.2f}\".format(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECE_539",
   "language": "python",
   "name": "ece_539"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
